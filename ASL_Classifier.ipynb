{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMUR_KeCMt9d"
   },
   "source": [
    "# Final ASL Classifier Pipeline\n",
    "\n",
    "This file will be the code implementation for the pipeline we are using to classify ASL letters.\n",
    "\n",
    "We will first need to import the necessary libraries as well as load in the training data. Then, we will define the Convolutional Neural Network class which our model is built from. Next, we define the following functions which we call in the two functions:\n",
    "- PreProcess: Takes in the training data/labels and the test data/labels. Outputs grayscale data in tensor form.\n",
    "- TrainModel: Takes in a model to be trained along with values for the training batch size, the number of epochs we are training for, a choice of loss function, the initial learning rate, and finally the pre-processed training data and labels. The function then trains the input model using those parameters.\n",
    "- EvaluteModel: Takes in the pre-processed test data and labels, loads a pre-trained model, then evaluates the model on the test set. Returns accuracy on the test set as well as the predicted class labels in a vector of letters.\n",
    "- PostProcess: Takes in the predicted class labels encoded as integers, then returns the labels as letters\n",
    "\n",
    "Next we define the two main functions, TrainFunction and TestFunction. These are pretty self-explanatory; the first trains a model and the second evalutes a pre-trained model. The only parameters passed into these two functions are data and labels, but they each call functions with other dependencies inside.\n",
    "\n",
    "Finally we will call these two functions, passing in the appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "vcPI-bnOSEbq",
    "outputId": "817f24a6-67d9-4741-de56-71e60a25ddcc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ac6914a3-0a13-4517-a04e-e81cadcc38ce\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-ac6914a3-0a13-4517-a04e-e81cadcc38ce\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving CNN_23.pt to CNN_23.pt\n",
      "Saving train_data.npy to train_data.npy\n",
      "Saving train_labels.npy to train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "# # # Load files to Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxbXfs5BV8PV"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Using PyTorch methods on training data\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import transforms as tv_tf\n",
    "\n",
    "# Import neural net\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load training data for train function\n",
    "train_data = np.load('provided_train_data.npy')\n",
    "train_labels = np.load('provided_train_labels.npy')\n",
    "\n",
    "test_data = np.load('provided_test_data.npy')\n",
    "test_labels = np.load('provided_test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Q2lwLz3fz-0"
   },
   "outputs": [],
   "source": [
    "# Define convolutional neural net class for grayscale images\n",
    "\n",
    "class ConvNetGray(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers - try reducing number of layers in linear layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        # self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5)\n",
    "        # Need to pass some garbage data to determine shape of input to linear layer\n",
    "        x = torch.randn(100,100).view(-1,1,100,100)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 9)\n",
    "\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        # x = F.max_pool2d(F.relu(self.conv4(x)), (2, 2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlAmOJAFY3vu"
   },
   "outputs": [],
   "source": [
    "# Preprocessing function:\n",
    "# Takes in data and labels, returns transformed data and labels\n",
    "# Transformations: Data will be converted to grayscale, labels will be encoded to be integers\n",
    "\n",
    "def PreProcess(data, labels):\n",
    "    # Convert training and test data to grayscale\n",
    "    X_gray = rgb2gray(data)\n",
    "    \n",
    "    # Encode class labels\n",
    "    LE = LabelEncoder()\n",
    "    y_flat = labels.ravel()\n",
    "    y_nums = LE.fit_transform(y_flat)\n",
    "    \n",
    "# Will possibly need to comment this out because changing the encoding to be 1-9 as opposed to 0-8 was throwing errors in training\n",
    "    # Adding 1 to each label to match required encoding format\n",
    "    for i in range(len(y_nums)):\n",
    "        y_nums[i] += 1\n",
    "        \n",
    "    # Convert to tensors\n",
    "    X_tn = torch.Tensor(X_gray)\n",
    "    y_tn = torch.Tensor(y_nums).type(torch.LongTensor)\n",
    "\n",
    "    return X_tn, y_tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCOzVGVjfv2J"
   },
   "outputs": [],
   "source": [
    "# Function to train a model\n",
    "# Parameters passed are an un-trained CNN model, Batch Size, Epochs, Loss Funtion, and Initial Learning Rate\n",
    "# We will also pass in the data with which we want to train the model - used for comparing the training sets\n",
    "\n",
    "def TrainModel(CNN, BatchSize, Epochs, Init_LR, X, y):\n",
    "    \n",
    "    print(\"Training above CNN with Batches of\", BatchSize, \"over\", Epochs, \"epochs...\")\n",
    "\n",
    "    BATCH_SIZE = BatchSize\n",
    "    EPOCHS = Epochs\n",
    "\n",
    "    opt = optim.Adam(CNN.parameters(), lr=Init_LR)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # New learning rate used for decay\n",
    "    New_LR = Init_LR\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(0, len(X), BATCH_SIZE): \n",
    "\n",
    "            batch_X = X[i:i+BATCH_SIZE].view(-1, 1, 100, 100)\n",
    "            batch_y = y[i:i+BATCH_SIZE]\n",
    "\n",
    "            CNN.zero_grad()\n",
    "            outputs = CNN(batch_X)\n",
    "            \n",
    "#             print(outputs)\n",
    "#             break\n",
    "            \n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # Learning rate decay based on epoch:\n",
    "        if (epoch < EPOCHS/2):\n",
    "            New_LR *= 0.999\n",
    "        else:\n",
    "            New_LR *= 0.99\n",
    "\n",
    "        opt = optim.Adam(CNN.parameters(), lr=New_LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDRSpO4ef_Do"
   },
   "outputs": [],
   "source": [
    "# Model evaluation function: Loads a pre-trained model and evaluates it using pre-processed test data w/ labels, outputs accuracy and predicted labels\n",
    "\n",
    "def EvaluateModel(model, X, y):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred_nums = np.zeros(len(y))\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            output = model(X[i].view(-1, 1, 100, 100))\n",
    "            y_true = y[i]\n",
    "            y_pred_nums[i] = torch.argmax(output) + 1 # This +1 is to match the output encoding of the labels\n",
    "            if y_true == y_pred_nums[i]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    return round(correct/total, 3), y_pred_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing function to convert the predicted labels from numbers to letters\n",
    "\n",
    "def PostProcess(labels, nums):\n",
    "    \n",
    "    # First we need to re-establish the initial transformation of labels to numbers\n",
    "    LE = LabelEncoder()\n",
    "    y_flat = labels.ravel()\n",
    "    y_nums = LE.fit_transform(y_flat)\n",
    "    \n",
    "    # Now we need to convert the predicted numbers to letters\n",
    "    # Convert nums from float to int\n",
    "    nums = nums.astype(int)\n",
    "\n",
    "# Will possibly need to comment this out because changing the encoding to be 1-9 as opposed to 0-8 was throwing errors in training\n",
    "    # Subtract 1 from each value before we do inverse_transform\n",
    "    for i in range(len(nums)):\n",
    "        nums[i] -= 1\n",
    "        \n",
    "    # Use inverse_transform method to revert encoding\n",
    "    letters = LE.inverse_transform(nums)\n",
    "    \n",
    "    return letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71NNG4l7g1az"
   },
   "source": [
    "Here are the two main functions, TrainFunction and TestFunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCKVTaILl22k"
   },
   "outputs": [],
   "source": [
    "# TrainFunction will take in the training data, pre-process it, generate an un-trained model, train that model, and return it\n",
    "def TrainFunction(X, y):\n",
    "\n",
    "    # First we pre-process the training data (it was loaded in the cell with the imports)\n",
    "    X_train, y_train = PreProcess(X, y)\n",
    "\n",
    "    # Next we instantiate an un-trained model and loss function\n",
    "    untrained_model = ConvNetGray()\n",
    "\n",
    "    # Train the un-trained model using the same parameters as we did for the model we saved\n",
    "    TrainModel(CNN=untrained_model, BatchSize=128, Epochs=2, Init_LR=0.001, X=X_train, y=y_train)\n",
    "    # untrained_model should now be trained so lets rename it\n",
    "    trained_model = untrained_model\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBCdzNvZpQvC"
   },
   "outputs": [],
   "source": [
    "# TestFunction will take in a dataset, pre-process it, then load a pre-trained model and evaluate it\n",
    "# Returns accuracy and predicted labels\n",
    "def TestFunction(X, y):\n",
    "\n",
    "    # First we pre-process the test data \n",
    "    X_test, y_test = PreProcess(X, y)\n",
    "\n",
    "    # Next we load in our pre-trained model\n",
    "    pretrained_model = torch.load('CNN_23.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "    # And now we evaluate a pre-trained model using the transformed test data\n",
    "    accuracy, predicted_nums = EvaluateModel(pretrained_model, X_test, y_test)\n",
    "    \n",
    "    # Finally do post-processing to get labels as letters\n",
    "    predicted_labels = PostProcess(labels=y, nums=predicted_nums)\n",
    "\n",
    "    return accuracy, predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwAVrnvArOZ-"
   },
   "source": [
    "Calling the two functions above to demonstrate functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__r6NaiLrMsB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897\n"
     ]
    }
   ],
   "source": [
    "# trained_model = TrainFunction(train_data, train_labels)\n",
    "# print(trained_model)\n",
    "\n",
    "accuracy, predicted_labels = TestFunction(test_data, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ASL_Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
